# ğŸ§ª Task_05_Descriptive_Stats

**Researcher**: Advait Narvekar  
**Institution**: Syracuse University  
**Reporting Period**: July 2025 â€“ Research Phase 1  
**Dataset**: 2021 Syracuse University Womenâ€™s Lacrosse Season Stats  
**LLM Evaluated**: ChatGPT (GPT-4)  
**Submission Email**: jrstrome@syr.edu  

---

## ğŸ“˜ Overview

This repository contains the descriptive statistics analysis and natural language reasoning task using a real-world dataset. The research evaluates the capabilities of a **Large Language Model (LLM)**â€”specifically ChatGPTâ€”to interpret sports performance data and derive actionable insights, simulating a coach-level decision-making scenario.

The dataset is **NOT INCLUDED** in this repository as per instructions.

---

## ğŸ¯ Objective

The primary goal of this task is to answer the research question:

> **â€œCan a Large Language Model (LLM) reliably interpret structured sports data and provide meaningful, explainable recommendations to improve team performance?â€**

To answer this, I used the official 2021 Syracuse Womenâ€™s Lacrosse dataset and tested ChatGPTâ€™s ability to:
- ğŸ” Retrieve accurate statistics
- ğŸ“Š Summarize and explain descriptive metrics
- ğŸ§  Provide strategic reasoning (e.g., whether to improve offense or defense)
- ğŸ’¬ Handle complex natural language queries
- âš  Recognize and report its own limitations

---

## ğŸ” Methodology

1. **Dataset Selection**  
   I selected the 2021 SU Womenâ€™s Lacrosse dataset because:
   - Itâ€™s compact but rich in statistics  
   - It includes both team and player-level data  
   - It reflects real-world sports scenarios where decisions impact game outcomes  

2. **Prompt Design**  
   I designed both factual and strategic prompts, such as:
   - â€œWho was the top scorer?â€
   - â€œWhatâ€™s the draw control rate?â€
   - â€œShould the coach focus on offense or defense to win 2 more games?â€

   **Justification**: This mixed difficulty tests both **data retrieval** and **inference skills** of the LLM.

3. **Evaluation Criteria**  
   Each response was reviewed based on:
   - âœ… **Accuracy**  
   - âœ… **Reasoning**  
   - âœ… **Contextual understanding**  
   - âœ… **Explanatory power**  

4. **Visualization Support**  
   Python scripts were written to generate key visualizations such as:
   - Top scorers' bar chart
   - Team vs opponent goal trends by half

   These helped **verify claims made by the LLM** and **support research reporting**.

---

## ğŸ” Research Constraints

- **No season-over-season data**: The dataset is from one year only. This made it difficult to determine trends like â€œmost improved playerâ€ without additional context. The LLM acknowledged this constraint and pivoted to identifying breakout players instead.
  
- **No qualitative variables**: Player morale, injuries, or opponent strategy were not part of the dataset. Hence, **LLM recommendations rely solely on quantitative indicators**.

- **LLM reasoning is prompt-dependent**: For high-quality results, I had to **refine prompts iteratively**, a key aspect of **prompt engineering**. Poorly worded prompts often returned vague or incorrect answers.

- **Visualizations not natively produced by LLM**: Although ChatGPT explained what to visualize, **I had to write the Python code manually** to produce supporting graphs.

---

## ğŸ“ˆ Key Results & Findings

| Question Type                | Accuracy | LLM Behavior |
|-----------------------------|----------|--------------|
| Simple Stats (e.g. top scorer) | âœ… 100%  | Immediate correct response |
| Descriptive Summaries       | âœ… 100%  | Aggregated and ranked values properly |
| Strategy Recommendation     | âœ… High  | Justified focus on defense using goal/foul/save metrics |
| Improvement Analysis        | âš  Partial | Correctly acknowledged lack of data |
| Visual Insight Explanation  | âœ…       | Recommended useful plots, but could not generate directly |

---

## ğŸ§  Final Recommendation by LLM

> **Focus on defense to improve season outcome.**  
> Syracuse already had a top-tier offense. However, data shows they allowed 57 free-position goals and had a modest save percentage (43.5%). Improving defenseâ€”especially reducing fouls and increasing goalie efficiencyâ€”could directly convert losses to wins.

**Suggested Player to Coach**:  
- ğŸ§¤ **Asa Goldstock** (Goalie) â€“ Improve save percentage  
- ğŸ›¡ï¸ **Sarah Cooper** (Defense) â€“ Reinforce ability to cause turnovers  
- ğŸ” **Ella Simkins** â€“ Critical for draw control dominance

---

## ğŸ’¡ Reflection

This project demonstrated that LLMs like ChatGPT:
- Can **reliably interpret structured statistics**  
- Can reason when asked strategic, coach-like questions  
- Struggle with **comparative metrics** when data is limited  
- Require **well-formed prompts** and visual aids for nuanced interpretation  

With proper constraints, LLMs can be powerful assistants in performance analysisâ€”not just for sports, but for any structured, metric-heavy domain.

---

## ğŸ“¨ Submission Instructions

- ğŸ“¤ Do **NOT upload the dataset** to GitHub  
- ğŸ“§ Email this repository link to: `jrstrome@syr.edu`  
- ğŸ•’ Submit by July 31st for Period 1 Reporting  
- ğŸ§¾ Complete the **OPT Progress Survey** here:  
  ğŸ‘‰ https://syracuseuniversity.qualtrics.com/jfe/form/SV_cDgnzM695AMx8d8

---